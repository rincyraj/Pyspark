{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLc0twYkWDMrNW3CEsQM5C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rincyraj/Pyspark/blob/main/spark_dataframe_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVCnYnWSnHTo",
        "outputId": "307b8b09-3cd4-46e8-e138-dad4fb22f4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.4\n",
            "<pyspark.sql.session.SparkSession object at 0x7aa3681e12d0>\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TestPySpark\").getOrCreate()\n",
        "print(spark.version)  # Should match your installed Spark version\n",
        "rincy = spark.getActiveSession()\n",
        "print(rincy)\n",
        "\n",
        "# Create sample data as list of lists\n",
        "data = [\n",
        "    [\"E001\", \"D001\", \"Alice\", \"30\", \"Female\", \"60000\", \"2015-06-23\"],\n",
        "    [\"E002\", \"D002\", \"Bob\", \"35\", \"Male\", \"75000\", \"2012-09-17\"],\n",
        "    [\"E003\", \"D001\", \"Charlie\", \"28\", \"Male\", \"55000\", \"2018-01-10\"],\n",
        "    [\"E004\", \"D003\", \"David\", \"40\", \"Male\", \"90000\", \"2010-12-01\"],\n",
        "    [\"E005\", \"D002\", \"Emma\", \"32\", \"Female\", \"72000\", \"2016-04-15\"],\n",
        "    [\"E006\", \"D004\", \"Frank\", \"29\", \"Male\", \"58000\", \"2019-03-11\"],\n",
        "    [\"E007\", \"D001\", \"Grace\", \"27\", \"Female\", \"62000\", \"2020-07-19\"],\n",
        "    [\"E008\", \"D003\", \"Hank\", \"45\", \"Male\", \"95000\", \"2009-05-21\"],\n",
        "    [\"E009\", \"D002\", \"Ivy\", \"33\", \"Female\", \"71000\", \"2017-09-30\"],\n",
        "    [\"E010\", \"D004\", \"Jack\", \"38\", \"Male\", \"78000\", \"2014-02-12\"],\n",
        "    [\"E011\", \"D001\", \"Karen\", \"26\", \"Female\", \"54000\", \"2021-11-05\"],\n",
        "    [\"E012\", \"D003\", \"Leo\", \"41\", \"Male\", \"88000\", \"2011-08-14\"],\n",
        "    [\"E013\", \"D002\", \"Mia\", \"34\", \"Female\", \"73000\", \"2015-10-22\"],\n",
        "    [\"E014\", \"D004\", \"Nina\", \"30\", \"Female\", \"61000\", \"2018-06-08\"],\n",
        "    [\"E015\", \"D001\", \"Oscar\", \"29\", \"Male\", \"57000\", \"2019-12-04\"],\n",
        "    [\"E016\", \"D003\", \"Paul\", \"37\", \"Male\", \"82000\", \"2013-03-29\"],\n",
        "    [\"E017\", \"D002\", \"Quinn\", \"31\", \"Female\", \"69000\", \"2016-07-17\"],\n",
        "    [\"E018\", \"D004\", \"Rachel\", \"28\", \"Female\", \"64000\", \"2019-05-25\"],\n",
        "    [\"E019\", \"D001\", \"Steve\", \"42\", \"Male\", \"89000\", \"2010-10-11\"],\n",
        "    [\"E020\", \"D003\", \"Tina\", \"39\", \"Female\", \"86000\", \"2012-04-06\"]\n",
        "]\n",
        "emp_schema = StructType([\n",
        "    StructField(\"employee_id\", StringType(), True),\n",
        "    StructField(\"department_id\", StringType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"age\", StringType(), True),\n",
        "    StructField(\"gender\", StringType(), True),\n",
        "    StructField(\"salary\", StringType(), True),\n",
        "    StructField(\"hire_date\", StringType(), True)\n",
        "])\n",
        "df = spark.createDataFrame(data, schema=emp_schema)\n",
        "df.show()\n",
        "df.rdd.getNumPartitions()\n",
        "# Create another  df with salary greter than 70000. Method 1\n",
        "df_high_salary = df.filter(df.salary > 70000)\n",
        "df_high_salary.show()\n",
        "#until we call an action, spark won't perform (lazy evaluation) Method2\n",
        "df_high_sal1 = df.where(\"salary>70000\")\n",
        "df_high_sal1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "2VTv1AzmkQ-b"
      }
    }
  ]
}