{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4razk+IZhaEF02QhF98Wx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rincyraj/Pyspark/blob/main/spark_data_frame_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVCnYnWSnHTo",
        "outputId": "8287f026-a386-4679-88e9-4628f8763d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.4\n",
            "<pyspark.sql.session.SparkSession object at 0x7e8d00aa8cd0>\n",
            "+-----------+-------------+-------+---+------+------+----------+\n",
            "|employee_id|department_id|   name|age|gender|salary| hire_date|\n",
            "+-----------+-------------+-------+---+------+------+----------+\n",
            "|       E001|         D001|  Alice| 30|Female| 60000|2015-06-23|\n",
            "|       E002|         D002|    Bob| 35|  Male| 75000|2012-09-17|\n",
            "|       E003|         D001|Charlie| 28|  Male| 55000|2018-01-10|\n",
            "|       E004|         D003|  David| 40|  Male| 90000|2010-12-01|\n",
            "|       E005|         D002|   Emma| 32|Female| 72000|2016-04-15|\n",
            "|       E006|         D004|  Frank| 29|  Male| 58000|2019-03-11|\n",
            "|       E007|         D001|  Grace| 27|Female| 62000|2020-07-19|\n",
            "|       E008|         D003|   Hank| 45|  Male| 95000|2009-05-21|\n",
            "|       E009|         D002|    Ivy| 33|Female| 71000|2017-09-30|\n",
            "|       E010|         D004|   Jack| 38|  Male| 78000|2014-02-12|\n",
            "|       E011|         D001|  Karen| 26|Female| 54000|2021-11-05|\n",
            "|       E012|         D003|    Leo| 41|  Male| 88000|2011-08-14|\n",
            "|       E013|         D002|    Mia| 34|Female| 73000|2015-10-22|\n",
            "|       E014|         D004|   Nina| 30|Female| 61000|2018-06-08|\n",
            "|       E015|         D001|  Oscar| 29|  Male| 57000|2019-12-04|\n",
            "|       E016|         D003|   Paul| 37|  Male| 82000|2013-03-29|\n",
            "|       E017|         D002|  Quinn| 31|Female| 69000|2016-07-17|\n",
            "|       E018|         D004| Rachel| 28|Female| 64000|2019-05-25|\n",
            "|       E019|         D001|  Steve| 42|  Male| 89000|2010-10-11|\n",
            "|       E020|         D003|   Tina| 39|Female| 86000|2012-04-06|\n",
            "+-----------+-------------+-------+---+------+------+----------+\n",
            "\n",
            "root\n",
            " |-- employee_id: string (nullable = true)\n",
            " |-- department_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            " |-- hire_date: string (nullable = true)\n",
            "\n",
            "Column<'name'>\n",
            "Column<'name'>\n",
            "Column<'name'>\n",
            "Column<'name'>\n",
            "+-----------+-----+------+---+\n",
            "|employee_id| name|salary|age|\n",
            "+-----------+-----+------+---+\n",
            "|       E002|  Bob| 75000| 35|\n",
            "|       E004|David| 90000| 40|\n",
            "|       E005| Emma| 72000| 32|\n",
            "|       E008| Hank| 95000| 45|\n",
            "|       E009|  Ivy| 71000| 33|\n",
            "|       E010| Jack| 78000| 38|\n",
            "|       E012|  Leo| 88000| 41|\n",
            "|       E013|  Mia| 73000| 34|\n",
            "|       E016| Paul| 82000| 37|\n",
            "|       E017|Quinn| 69000| 31|\n",
            "|       E019|Steve| 89000| 42|\n",
            "|       E020| Tina| 86000| 39|\n",
            "+-----------+-----+------+---+\n",
            "\n",
            "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True)])\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TestPySpark\").getOrCreate()\n",
        "print(spark.version)  # Should match your installed Spark version\n",
        "rincy = spark.getActiveSession()\n",
        "print(rincy)\n",
        "\n",
        "# Create sample data as list of lists\n",
        "data = [\n",
        "    [\"E001\", \"D001\", \"Alice\", \"30\", \"Female\", \"60000\", \"2015-06-23\"],\n",
        "    [\"E002\", \"D002\", \"Bob\", \"35\", \"Male\", \"75000\", \"2012-09-17\"],\n",
        "    [\"E003\", \"D001\", \"Charlie\", \"28\", \"Male\", \"55000\", \"2018-01-10\"],\n",
        "    [\"E004\", \"D003\", \"David\", \"40\", \"Male\", \"90000\", \"2010-12-01\"],\n",
        "    [\"E005\", \"D002\", \"Emma\", \"32\", \"Female\", \"72000\", \"2016-04-15\"],\n",
        "    [\"E006\", \"D004\", \"Frank\", \"29\", \"Male\", \"58000\", \"2019-03-11\"],\n",
        "    [\"E007\", \"D001\", \"Grace\", \"27\", \"Female\", \"62000\", \"2020-07-19\"],\n",
        "    [\"E008\", \"D003\", \"Hank\", \"45\", \"Male\", \"95000\", \"2009-05-21\"],\n",
        "    [\"E009\", \"D002\", \"Ivy\", \"33\", \"Female\", \"71000\", \"2017-09-30\"],\n",
        "    [\"E010\", \"D004\", \"Jack\", \"38\", \"Male\", \"78000\", \"2014-02-12\"],\n",
        "    [\"E011\", \"D001\", \"Karen\", \"26\", \"Female\", \"54000\", \"2021-11-05\"],\n",
        "    [\"E012\", \"D003\", \"Leo\", \"41\", \"Male\", \"88000\", \"2011-08-14\"],\n",
        "    [\"E013\", \"D002\", \"Mia\", \"34\", \"Female\", \"73000\", \"2015-10-22\"],\n",
        "    [\"E014\", \"D004\", \"Nina\", \"30\", \"Female\", \"61000\", \"2018-06-08\"],\n",
        "    [\"E015\", \"D001\", \"Oscar\", \"29\", \"Male\", \"57000\", \"2019-12-04\"],\n",
        "    [\"E016\", \"D003\", \"Paul\", \"37\", \"Male\", \"82000\", \"2013-03-29\"],\n",
        "    [\"E017\", \"D002\", \"Quinn\", \"31\", \"Female\", \"69000\", \"2016-07-17\"],\n",
        "    [\"E018\", \"D004\", \"Rachel\", \"28\", \"Female\", \"64000\", \"2019-05-25\"],\n",
        "    [\"E019\", \"D001\", \"Steve\", \"42\", \"Male\", \"89000\", \"2010-10-11\"],\n",
        "    [\"E020\", \"D003\", \"Tina\", \"39\", \"Female\", \"86000\", \"2012-04-06\"]\n",
        "]\n",
        "emp_schema = StructType([\n",
        "    StructField(\"employee_id\", StringType(), True),\n",
        "    StructField(\"department_id\", StringType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"age\", StringType(), True),\n",
        "    StructField(\"gender\", StringType(), True),\n",
        "    StructField(\"salary\", StringType(), True),\n",
        "    StructField(\"hire_date\", StringType(), True)\n",
        "])\n",
        "df = spark.createDataFrame(data, schema=emp_schema)\n",
        "df.show()\n",
        "df.rdd.getNumPartitions()\n",
        "# Create another  df with salary greter than 70000. Method 1\n",
        "df_high_salary = df.filter(df.salary > 70000)\n",
        "# Action\n",
        "# df_high_salary.show()\n",
        "#until we call an action, spark won't perform (lazy evaluation) Method2\n",
        "df_high_sal1 = df.where(\"salary>70000\")\n",
        "# Action\n",
        "# df_high_sal1.show()\n",
        "# To see the schema\n",
        "df.printSchema()#[Column, column datatype,nullable]\n",
        "df.schema\n",
        "#cOLUMNS,EXpr\n",
        "print(df.name)\n",
        "print(df['name'])\n",
        "from pyspark.sql.functions import col, expr # Import col and expr\n",
        "print(col(\"name\"))\n",
        "print(expr(\"name\"))\n",
        "# Select columns:\n",
        "emp_filtered = df.select(\"employee_id\", \"name\", \"salary\")\n",
        "# emp_filtered.show()\n",
        "# Another methoid\n",
        "emp1 = df.select(df.employee_id, col(\"name\"), expr(\"salary\"))\n",
        "# emp1.show()\n",
        "#Type casting\n",
        "emp_casted =df.select(expr(\"employee_id as emp_id\"),expr(\"cast(age as int) as age\"))\n",
        "# emp_casted.show()\n",
        "# emp_casted.printSchema()\n",
        "# Another method for selectexpr(select and cast)\n",
        "emp_casted1 = df.selectExpr(\"employee_id as emp_id\",\"cast(age as int) as age\")\n",
        "# emp_casted1.show()\n",
        "emp_final = df.select(\"employee_id\",\"name\",\"salary\",\"age\").where(\"age>30\")\n",
        "# emp_final.show()\n",
        "#saving\n",
        "emp_final.write.format(\"csv\").save(\"emp_final.csv\")\n",
        "#Bonustip1, spark can identify native spark data schema from the type we provides\n",
        "schema_str=\"name string, age int\"\n",
        "from pyspark.sql.types import _parse_datatype_string\n",
        "spark_schema= _parse_datatype_string(schema_str)\n",
        "print(spark_schema)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lazy evaluation: Will not perform  transformations until the action call.\n",
        "Select,expr,SelectExpr,cast"
      ],
      "metadata": {
        "id": "2VTv1AzmkQ-b"
      }
    }
  ]
}